import pickle
import shap
import torch
import xgboost as xgb
import sys
import numpy as np

# Wrapper for the XGBoost classifier that makes it work for multiclass classification
class XGBC(object):
    def __init__(self, num_round = 2, max_depth = 2, eta= 1.0, min_child_weight = 2, colsample_bytree = 1, objective = 'multi:softprob'):
        self.max_depth = max_depth
        self.eta = eta
        self.colsample_bytree = colsample_bytree
        self.num_round = num_round
        self.min_child_weight = min_child_weight
        self.objective = objective
    def fit(self, train, label):
        dtrain = xgb.DMatrix(train, label = label, missing = -999)
        param = {'max_depth':self.max_depth, 'eta':self.eta,
        'colsample_bytree': self.colsample_bytree, 'min_child_weight': self.min_child_weight, 'objective':self.objective,
        'num_class':len(considered_classes)}
        self.bst = xgb.train(param, dtrain, self.num_round)
    def predict_proba(self, test):
        dtest = xgb.DMatrix(test, missing = -999)
        ypred = self.bst.predict(dtest)
        return ypred
    # Attempting to use out-of-the-box explainers for XGBoost which perform better (usually)
    def get_bst(self):
        return self.bst

# Returns a normalized array of probabilities
# There are many issues with that:
# 1) It takes a long time to get the explanations
# 2) Classifier outputs are dependent because of the normalization process
def shap_model_output_nn(data):
	predictions = []
	for sample in data:
		prediction = []
		for class_ in considered_classes:
			prediction.append(float(classifiers[class_](torch.from_numpy(sample))[0]))
		prediction = [x/sum(prediction) for x in prediction]
		predictions.append(prediction)
	return np.array(predictions)

def shap_model_output_xgboost(data):
	return classifiers.predict_proba(data)

class ExplanationGenerator:
	def __init__(self, index):
		self.index = index
		self.filename = "{}_{}_{}_batch_{}".format(feature, model, explainer, index)

	def generate_explanations_to_file(self):
		data = pickle.load(open("{}_{}_{}_batch_{}".format(feature, model, explainer, self.index), 'rb'))
		malw_feats = data[0]

		shap_sample = pickle.load(open("shap_sample.pickle", "rb"))

		selected_function = shap_model_output_nn if model == '2layernn' else shap_model_output_xgboost

		explainer_ = shap.KernelExplainer(selected_function, shap_sample)

		shap_values = explainer_.shap_values(malw_feats, nsamples=500)

		print(len(shap_values), flush=True)
	
		print(len(shap_values[0]), flush=True)
	
		pickle.dump(shap_values, open("{}_{}_{}_result_batch_{}".format(feature, model, explainer, self.index), "wb")) 

index = sys.argv[1]
feature = sys.argv[2]
model = sys.argv[3]
explainer = sys.argv[4]
classifiers = pickle.load(open("classifiers.pickle", "rb")) 
considered_classes = pickle.load(open("considered_classes.pickle", "rb"))
eg = ExplanationGenerator(index)
eg.generate_explanations_to_file()
