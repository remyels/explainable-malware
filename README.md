# explainable-malware

_Most of the code involves components that require parallelization/a decent amount of RAM, so experiments were run with the help of the AUB Octopus cluster: this explains why no .ipynb files are involved. To ensure that encountered issues are minimized, clone the project into the AUB cluster; things should work right out of the box!_

## Part 0: The workflow

The main purpose of the project is to determine the robustness of explanation gathering of a given dataset across different generated features, different classifiers and different explainers. The code included in this repository takes care of the generation of explanations given a selected feature set, classifier and explainer. More details can be found in the visualized workflow in the "workflow" directory, in which I also included the raw file for your convenience (visit  [draw.io](http://draw.io) to make edits).

## Part 1: Feature generation

The components related to this part can be found under the "feature_gen" directory. We make use of two feature sets: an ngram-based feature set and a more complicated feature set that was engineered by the winners of the Microsoft Malware Classification Challenge (which you can find [here](https://github.com/xiaozhouwang/kaggle_Microsoft_Malware)). Code to generate the ngram-based feature set can be found below:

1. Download the dataset that the research is based on. You can find the dataset [here](https://www.kaggle.com/c/malware-classification). You will need the train.7z and the trainLabels.csv file.
2. Convert train.7z to train.zip. The easiest way to do that is using an application such as Bitser, which you can download the latest version of from [here](https://www.bitser.org/download_zip.shtml).
3. Run malware_to_ngram_to_occ.py, and once it is done, run family_to_ngram_to_occ.py. Feel free to delete the malware_ngrams folder.

Alternatively, if you do not want to go through the whole process for both ngram-based features and the engineered feature set, feel free to contact me and I would be more than happy to provide you with both feature sets.

## Part 2: Running the experiments

Now that the required feature sets are ready, the next step is running the experiments and obtaining the results. Before you do that, you are greatly encouraged to read what purpose each of the included files under "src" serves.

* trainLabels.csv: contains the labels of the malware considered in our dataset.
* generalized_workflow.py: runs a single experiment (the code that gets run depends on the command line arguments passed).
* single_experiment.py: a script that creates a job for a single job (this file also contains the required libraries as well as their version). The way this works is by calling on thhe generalized_workflow.py file with specific arguments. When running the generalized_workflow.py file, you may pass an optional "debug" flag at the end in order to run the code on the smallest 2 classes (as a way to check whether there are any issues with the code, instead of having to wait for all 9 classes to be processed, and end up encountering an issue later on after waiting for a few hours).

Knowing how running a single experiment is done, I generated 16 script files, one for each combination: those can be found under job_files. The next obvious step would be to run those simultaneously, and that's something that can be easily achieved. I have also included the code that generates the 16 batch files under job_files, in case there are any modifications to be made in that regard.

* explanation_jobs_runner.py: runs all experiments simultaneously by running a total of 16 batch jobs.

Now let us take a look at the rest of the files in more detail, in order to figure out the purpose that they achieve. The code that we run involves very serial lengthy computations (specifically in the explanation generation part), which is why we opted to run multiple batches for each experiment, such that each batch generates the explanations for a subset of the malware instances.

* explainer_batch_generator_runner.py: This file generates a script file that runs a Python script that generates the explanations for a subset of the malware instances. Takes the batch index, feature set selected, classifier selected and explainer selected as input.
* explanation_generator.py: This is the Python program that generates the explanations for a subset of the malware instances. Is run as part of a batch job launched by the .sh file created by the Python program above.

The above covers all the code that is integral to the functioning of the experiments. I have included a few extra pieces of Python code that may be useful.

* delete_results.py: Deletes all the experiment results
* count_result_files.py: Checks the number of files resulting from running all the experiments, and checks which folders are still empty. 
